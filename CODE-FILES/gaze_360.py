# -*- coding: utf-8 -*-
"""Gaze_360.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13QOZA2JicpFmSnnPjzthnxy6VItuiJlF
"""

##ML mpdel using gaze 360 Dataset

from google.colab import drive
drive.mount('/content/drive')

#drive.mount('/content/drive')

import os

def list_folder(path, level=0):
    try:
        for item in os.listdir(path):
            item_path = os.path.join(path, item)
            print("    " * level + "├── " + item)
            if os.path.isdir(item_path):
                list_folder(item_path, level + 1)
    except Exception as e:
        print(f"Error accessing {path}: {e}")


folder_path = '/content/drive/MyDrive/gaze360-master'

if os.path.exists(folder_path):
    print(f"\n  Listing contents of: {folder_path}\n")
    list_folder(folder_path)
else:
    print(f"\n  Folder not found: {folder_path}")

import os

def print_directory_tree(root_dir, indent=""):
    try:
        items = sorted(os.listdir(root_dir))
    except Exception as e:
        print(f"{indent}[Error reading {root_dir}]: {e}")
        return

    for item in items:
        path = os.path.join(root_dir, item)
        if os.path.isdir(path):
            print(f"{indent} {item}/")
            print_directory_tree(path, indent + "    ")
        else:
            print(f"{indent} {item}")


root_path = "/content/drive/MyDrive/gaze360-master"
print(f"\n Exploring contents of: {root_path}\n")
print_directory_tree(root_path)

#checking train.txt

with open("/content/drive/MyDrive/gaze360-master/code/train.txt", "r") as f:
    for i in range(10):
        print(f.readline().strip())

##try code for random 100 images rgb

import os
import numpy as np
from PIL import Image
import random

#path of the data
base_path = "/content/drive/MyDrive/gaze360-master/my_data"
image_dir = os.path.join(base_path, "rec_001", "head", "000000")
os.makedirs(image_dir, exist_ok=True)

# 100 images
train_lines = []
start_index = 1620
for i in range(100):
    img_name = f"{start_index + i:06d}.jpg"
    img_path = os.path.join(image_dir, img_name)
#random RGB image (224x224)
    img = np.random.randint(0, 256, (224, 224, 3), dtype=np.uint8)
    Image.fromarray(img).save(img_path)

    #gaze vector
    gaze = [round(random.uniform(-1, 1), 6) for _ in range(3)]


    relative_path = f"rec_001/head/000000/{img_name}"
    train_lines.append(f"{relative_path} {gaze[0]} {gaze[1]} {gaze[2]}")

#  train.txt
train_txt_path = os.path.join(base_path, "train.txt")
with open(train_txt_path, "w") as f:
    f.write("\n".join(train_lines))

print(" \n Created 100 dummy images and train.txt at:")
print(train_txt_path)

#view file header
!head -n 40 "/content/drive/MyDrive/gaze360-master/code/data_loader.py"

import os
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import torch
import torchvision.transforms as transforms

class SimpleGazeDataset(Dataset):
    def __init__(self, txt_file, root_dir):
        with open(txt_file, "r") as f:
            lines = f.readlines()

        self.samples = []
        for line in lines:
            parts = line.strip().split()
            if len(parts) != 4:
                continue
            img_path = os.path.join(root_dir, parts[0])
            gaze = torch.tensor([float(parts[1]), float(parts[2]), float(parts[3])], dtype=torch.float32)
            self.samples.append((img_path, gaze))

        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, gaze = self.samples[idx]
        image = Image.open(img_path).convert("RGB")
        image = self.transform(image)
        return image, gaze

# paths
txt_path = "/content/drive/MyDrive/gaze360-master/my_data/train.txt"
data_root = "/content/drive/MyDrive/gaze360-master/my_data"

# Creating loader
dataset = SimpleGazeDataset(txt_path, data_root)
loader = DataLoader(dataset, batch_size=4, shuffle=True)

#  one batch
images, gazes = next(iter(loader))
print(" Simplified loader works!")
print(f"Images shape: {images.shape}")  # (B, 3, 224, 224)
print(f"Gazes shape: {gazes.shape}")    # (B, 3)
print(f"Sample gaze vector: {gazes[0]}")

import os
import torch
import torch.nn as nn
import torch.optim as optim
from PIL import Image
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms


# Step 1: Dataset Loader

class SimpleGazeDataset(Dataset):
    def __init__(self, txt_file, root_dir):
        with open(txt_file, "r") as f:
            lines = f.readlines()

        self.samples = []
        for line in lines:
            parts = line.strip().split()
            if len(parts) != 4:
                continue
            img_path = os.path.join(root_dir, parts[0])
            gaze = torch.tensor([float(parts[1]), float(parts[2]), float(parts[3])], dtype=torch.float32)
            self.samples.append((img_path, gaze))

        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, gaze = self.samples[idx]
        image = Image.open(img_path).convert("RGB")
        image = self.transform(image)
        return image, gaze

##cnn
class SimpleGazeCNN(nn.Module):
    def __init__(self):
        super(SimpleGazeCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 112x112

            nn.Conv2d(32, 64, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 56x56

            nn.Conv2d(64, 128, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 28x28
        )
        self.fc = nn.Sequential(
            nn.Linear(128 * 28 * 28, 256),
            nn.ReLU(),
            nn.Linear(256, 3)  # Gaze output (x, y, z)
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        return self.fc(x)


#training

def train_model():
    # Paths
    base_path = "/content/drive/MyDrive/gaze360-master/my_data"
    train_txt = os.path.join(base_path, "train.txt")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Load data
    dataset = SimpleGazeDataset(train_txt, base_path)
    loader = DataLoader(dataset, batch_size=8, shuffle=True)

    # Model, optimizer, loss
    model = SimpleGazeCNN().to(device)
    optimizer = optim.Adam(model.parameters(), lr=1e-4)
    criterion = nn.MSELoss()

    num_epochs = 100

    for epoch in range(num_epochs):
        model.train()
        total_loss = 0.0
        for images, gazes in loader:
            images = images.to(device)
            gazes = gazes.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, gazes)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        avg_loss = total_loss / len(loader)
        print(f"Epoch [{epoch+1}/{num_epochs}]  Loss: {avg_loss:.6f}")

    # Save model
    torch.save(model.state_dict(), os.path.join(base_path, "gaze_model_dummy.pth"))
    print(" Training complete. Model saved to 'gaze_model_dummy.pth'.")



train_model()

#predicted gaze vs actual

import os
import torch
import torch.nn as nn
from torch.utils.data import Dataset
from PIL import Image
import torchvision.transforms as transforms
import random


class SimpleGazeCNN(nn.Module):
    def __init__(self):
        super(SimpleGazeCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(32, 64, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(64, 128, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),
        )
        self.fc = nn.Sequential(
            nn.Linear(128 * 28 * 28, 256),
            nn.ReLU(),
            nn.Linear(256, 3)
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        return self.fc(x)


class SimpleGazeDataset(Dataset):
    def __init__(self, txt_file, root_dir):
        with open(txt_file, "r") as f:
            lines = f.readlines()

        self.samples = []
        for line in lines:
            parts = line.strip().split()
            if len(parts) != 4:
                continue
            img_path = os.path.join(root_dir, parts[0])
            gaze = torch.tensor([float(parts[1]), float(parts[2]), float(parts[3])], dtype=torch.float32)
            self.samples.append((img_path, gaze))

        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, gaze = self.samples[idx]
        image = Image.open(img_path).convert("RGB")
        image = self.transform(image)
        return image, gaze


def predict_samples():
    model_path = "/content/drive/MyDrive/gaze360-master/my_data/gaze_model_dummy.pth"
    data_path = "/content/drive/MyDrive/gaze360-master/my_data"
    txt_path = os.path.join(data_path, "train.txt")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Load model
    model = SimpleGazeCNN().to(device)
    model.load_state_dict(torch.load(model_path))
    model.eval()

    # Load dataset
    dataset = SimpleGazeDataset(txt_path, data_path)

    print("\n Predictions on 50 random samples:\n")
    for i in random.sample(range(len(dataset)), 50):
        image, true_gaze = dataset[i]
        input_tensor = image.unsqueeze(0).to(device)

        with torch.no_grad():
            predicted_gaze = model(input_tensor)[0].cpu()

        print(f"Sample {i}:")
        print(f"   Predicted gaze: {predicted_gaze.numpy()}")
        print(f"   Ground truth : {true_gaze.numpy()}\n")

# Run
predict_samples()

import os
import torch
import torch.nn as nn
from torch.utils.data import Dataset
from PIL import Image
import torchvision.transforms as transforms
import numpy as np
import math


class SimpleGazeCNN(nn.Module):
    def __init__(self):
        super(SimpleGazeCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),
        )
        self.fc = nn.Sequential(
            nn.Linear(128 * 28 * 28, 256),
            nn.ReLU(),
            nn.Linear(256, 3)
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        return self.fc(x)



class SimpleGazeDataset(Dataset):
    def __init__(self, txt_file, root_dir):
        with open(txt_file, "r") as f:
            lines = f.readlines()

        self.samples = []
        for line in lines:
            parts = line.strip().split()
            if len(parts) != 4:
                continue
            img_path = os.path.join(root_dir, parts[0])
            gaze = torch.tensor([float(parts[1]), float(parts[2]), float(parts[3])], dtype=torch.float32)
            self.samples.append((img_path, gaze))

        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, gaze = self.samples[idx]
        image = Image.open(img_path).convert("RGB")
        image = self.transform(image)
        return image, gaze


# Angular error

def angular_error(pred, true):
    pred_norm = pred / torch.norm(pred)
    true_norm = true / torch.norm(true)
    dot_product = torch.dot(pred_norm, true_norm).clamp(-1.0, 1.0)
    angle = torch.acos(dot_product) * 180 / math.pi  # in degrees
    return angle.item()


# Evaluate Accuracy

def evaluate_model():
    model_path = "/content/drive/MyDrive/gaze360-master/my_data/gaze_model_dummy.pth"
    data_path = "/content/drive/MyDrive/gaze360-master/my_data"
    txt_path = os.path.join(data_path, "train.txt")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Load model
    model = SimpleGazeCNN().to(device)
    model.load_state_dict(torch.load(model_path))
    model.eval()

    # Load dataset
    dataset = SimpleGazeDataset(txt_path, data_path)

    total_angle = 0.0
    with torch.no_grad():
        for img, true_gaze in dataset:
            img = img.unsqueeze(0).to(device)
            pred_gaze = model(img)[0].cpu()
            angle = angular_error(pred_gaze, true_gaze)
            total_angle += angle

    avg_angle = total_angle / len(dataset)
    print(f"\n Average Angular Error: {avg_angle:.2f} degrees")

# Run
evaluate_model()

import os
import torch
import torch.nn as nn
from torch.utils.data import Dataset
from PIL import Image
import torchvision.transforms as transforms
import random



class SimpleGazeCNN(nn.Module):
    def __init__(self):
        super(SimpleGazeCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(32, 64, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(64, 128, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),
        )
        self.fc = nn.Sequential(
            nn.Linear(128 * 28 * 28, 256),
            nn.ReLU(),
            nn.Linear(256, 3)
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        return self.fc(x)


class SimpleGazeDataset(Dataset):
    def __init__(self, txt_file, root_dir):
        with open(txt_file, "r") as f:
            lines = f.readlines()

        self.samples = []
        for line in lines:
            parts = line.strip().split()
            if len(parts) != 4:
                continue
            img_path = os.path.join(root_dir, parts[0])
            gaze = torch.tensor([float(parts[1]), float(parts[2]), float(parts[3])], dtype=torch.float32)
            self.samples.append((img_path, gaze))

        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, gaze = self.samples[idx]
        image = Image.open(img_path).convert("RGB")
        image = self.transform(image)
        return image, gaze


# Predict

def predict_samples():
    model_path = "/content/drive/MyDrive/gaze360-master/my_data/gaze_model_dummy.pth"
    data_path = "/content/drive/MyDrive/gaze360-master/my_data"
    txt_path = os.path.join(data_path, "train.txt")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Load model
    model = SimpleGazeCNN().to(device)
    model.load_state_dict(torch.load(model_path))
    model.eval()

    # Load dataset
    dataset = SimpleGazeDataset(txt_path, data_path)

    print("\n Predictions on 100 random samples:\n")
    for i in random.sample(range(len(dataset)), 100):
        image, true_gaze = dataset[i]
        input_tensor = image.unsqueeze(0).to(device)

        with torch.no_grad():
            predicted_gaze = model(input_tensor)[0].cpu()

        print(f"Sample {i}:")
        print(f"   Predicted gaze: {predicted_gaze.numpy()}")
        print(f"   Ground truth : {true_gaze.numpy()}\n")

# Run
predict_samples()

import os
import torch
import torch.nn as nn
from torch.utils.data import Dataset
from PIL import Image
import torchvision.transforms as transforms
import numpy as np
import math


class SimpleGazeCNN(nn.Module):
    def __init__(self):
        super(SimpleGazeCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),
        )
        self.fc = nn.Sequential(
            nn.Linear(128 * 28 * 28, 256),
            nn.ReLU(),
            nn.Linear(256, 3)
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        return self.fc(x)

class SimpleGazeDataset(Dataset):
    def __init__(self, txt_file, root_dir):
        with open(txt_file, "r") as f:
            lines = f.readlines()

        self.samples = []
        for line in lines:
            parts = line.strip().split()
            if len(parts) != 4:
                continue
            img_path = os.path.join(root_dir, parts[0])
            gaze = torch.tensor([float(parts[1]), float(parts[2]), float(parts[3])], dtype=torch.float32)
            self.samples.append((img_path, gaze))

        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, gaze = self.samples[idx]
        image = Image.open(img_path).convert("RGB")
        image = self.transform(image)
        return image, gaze

# Angular erors

def angular_error(pred, true):
    pred_norm = pred / torch.norm(pred)
    true_norm = true / torch.norm(true)
    dot_product = torch.dot(pred_norm, true_norm).clamp(-1.0, 1.0)
    angle = torch.acos(dot_product) * 180 / math.pi  # in degrees
    return angle.item()

# Evaluate
def evaluate_model():
    model_path = "/content/drive/MyDrive/gaze360-master/my_data/gaze_model_dummy.pth"
    data_path = "/content/drive/MyDrive/gaze360-master/my_data"
    txt_path = os.path.join(data_path, "train.txt")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Load model
    model = SimpleGazeCNN().to(device)
    model.load_state_dict(torch.load(model_path))
    model.eval()

    # Load dataset
    dataset = SimpleGazeDataset(txt_path, data_path)

    total_angle = 0.0
    with torch.no_grad():
        for img, true_gaze in dataset:
            img = img.unsqueeze(0).to(device)
            pred_gaze = model(img)[0].cpu()
            angle = angular_error(pred_gaze, true_gaze)
            total_angle += angle

    avg_angle = total_angle / len(dataset)
    print(f"\n Average Angular Error: {avg_angle:.2f} degrees")

# Run
evaluate_model()

!ls /content/drive/MyDrive/gaze360-master/dataset/



# Downloading Gaze360 dataset
!wget -O /content/Gaze360.tar "http://gaze360.csail.mit.edu/dataset.php?email=divyansh.saini@iitgn.ac.in&hash=941e1aaaba585b952b62c14a3a175a61"

# Extracting
!mkdir -p /content/drive/MyDrive/gaze360-master/dataset
!tar -xf /content/Gaze360.tar -C /content/drive/MyDrive/gaze360-master/dataset

!ls /content/drive/MyDrive/gaze360-master/dataset/images/rec_001/head/000000/ | head
!head -n 5 /content/drive/MyDrive/gaze360-master/code/train.txt

#tar-file
!mkdir -p /content/drive/MyDrive/gaze360-master/dataset
!tar -xf /content/Gaze360.tar -C /content/drive/MyDrive/gaze360-master/dataset

from google.colab import drive
drive.mount('/content/drive')

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt


# Dataset Class

class Gaze360Dataset(Dataset):
    def __init__(self, txt_file, root_dir):
        with open(txt_file, 'r') as f:
            lines = f.readlines()

        self.samples = []
        for line in lines:
            parts = line.strip().split()
            if len(parts) != 4:
                continue
            image_path = os.path.join(root_dir, parts[0])
            if os.path.exists(image_path):
                gaze = torch.tensor([float(p) for p in parts[1:4]], dtype=torch.float32)
                self.samples.append((image_path, gaze))

        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, gaze = self.samples[idx]
        image = Image.open(img_path).convert("RGB")
        image = self.transform(image)
        return image, gaze


# Model Definition

class SimpleGazeCNN(nn.Module):
    def __init__(self):
        super(SimpleGazeCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, kernel_size=5, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(2),
        )
        self.fc = nn.Sequential(
            nn.Linear(128 * 28 * 28, 256),
            nn.ReLU(),
            nn.Linear(256, 3)
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        return self.fc(x)


# Training Function

def train_model():
    DATA_PATH = "/content/drive/MyDrive/gaze360-master/dataset/imgs"
    TXT_FILE = "/content/drive/MyDrive/gaze360-master/my_data/train.txt"

    dataset = Gaze360Dataset(txt_file=TXT_FILE, root_dir=DATA_PATH)

    if len(dataset) == 0:
        raise ValueError("No valid images found. Check your image paths.")

    loader = DataLoader(dataset, batch_size=32, shuffle=True)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    model = SimpleGazeCNN().to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-4)

    num_epochs = 100
    loss_history = []

    for epoch in range(num_epochs):
        model.train()
        total_loss = 0.0

        for images, gazes in loader:
            images, gazes = images.to(device), gazes.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, gazes)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        avg_loss = total_loss / len(loader)
        loss_history.append(avg_loss)
        print(f"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.6f}")


    model_path = os.path.join(DATA_PATH, "gaze360_model.pth")
    torch.save(model.state_dict(), model_path)
    print(f" Model saved to: {model_path}")

    #  loss curve
    plt.figure(figsize=(10, 4))
    plt.plot(range(1, num_epochs + 1), loss_history, label="Training Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Training Loss over Epochs")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.show()

    return model, dataset


# Train

model, dataset = train_model()

#phase angle

import torch
import torch.nn.functional as F
import math
from torch.utils.data import DataLoader

#angular error
def angular_error(pred, true):
    pred = F.normalize(pred, dim=-1)
    true = F.normalize(true, dim=-1)
    dot_product = (pred * true).sum(dim=-1).clamp(-1.0, 1.0)
    angles = torch.acos(dot_product)
    return angles * 180.0 / math.pi  # radians to degrees


# Evaluation Script

def evaluate_model(model, dataset):
    loader = DataLoader(dataset, batch_size=32, shuffle=False)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    model.eval()

    all_errors = []

    with torch.no_grad():
        for images, true_gazes in loader:
            images, true_gazes = images.to(device), true_gazes.to(device)
            predicted_gazes = model(images)
            errors = angular_error(predicted_gazes, true_gazes)
            all_errors.extend(errors.cpu().numpy())

    mean_error = sum(all_errors) / len(all_errors)
    print(f" \n  Mean Angular Error: {mean_error:.2f} degrees")
    return all_errors


# Evaluation
errors = evaluate_model(model, dataset)

avg_error = sum(errors) / len(errors)
print("Average Angular Error:", round(avg_error, 2), "degrees")



